{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\tools\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\tools\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\tools\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\tools\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\tools\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\tools\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\moham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download NLTK punkt sentence tokenizer (if not already downloaded)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Download NLTK averaged perceptron POS tagger (if not already downloaded)\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tags(sentences):\n",
    "    \"\"\"\n",
    "    This function takes a list of sentences and returns a list of lists containing POS tags.\n",
    "    \"\"\"\n",
    "    pos_tagged_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence into words\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        # Get POS tags for each token\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "        pos_tagged_sentences.append(pos_tags)\n",
    "    return pos_tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grams(pos_tagged_sentences):\n",
    "    \"\"\"\n",
    "    This function takes a list of POS-tagged sentences and returns a dictionary containing 1-grams and 2-grams for each sentence.\n",
    "    \"\"\"\n",
    "    grams_dict = {}\n",
    "    for i, sentence in enumerate(pos_tagged_sentences):\n",
    "        grams = {\"1-grams\": [], \"2-grams\": []}\n",
    "        for word, tag in sentence:\n",
    "            grams[\"1-grams\"].append(tag)\n",
    "            if len(sentence) > 1 and sentence.index((word, tag)) < len(sentence) - 1:\n",
    "                next_word, next_tag = sentence[sentence.index((word, tag)) + 1]\n",
    "                grams[\"2-grams\"].append((tag, next_tag))\n",
    "        grams_dict[f\"Sentence {i+1}\"] = grams\n",
    "    return grams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"\n",
    "    This function calculates the Jaccard similarity between two sets,\n",
    "    along with union and intersection counts.\n",
    "    \"\"\"\n",
    "    intersection_count = 0\n",
    "    union = len(set1 | set2)  # Union of sets\n",
    "    for element in set1:\n",
    "        if element in set2:\n",
    "            intersection_count += 1\n",
    "    jaccard_value = intersection_count / float(union) if union else 0\n",
    "    return jaccard_value, intersection_count, union  # Return additional values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard(grams_dict):\n",
    "    \"\"\"\n",
    "    This function calculates Jaccard similarity for 1-grams and 2-grams between all sentence pairs,\n",
    "    also displaying the union and intersection counts.\n",
    "    \"\"\"\n",
    "    for i, sentence1 in enumerate(grams_dict.values()):\n",
    "        for j, sentence2 in enumerate(grams_dict.values()):\n",
    "            if i != j:\n",
    "                # Calculate Jaccard for 1-grams\n",
    "                jaccard_1gram, intersection_1gram, union_1gram = jaccard_similarity(\n",
    "                    set(sentence1[\"1-grams\"]), set(sentence2[\"1-grams\"])\n",
    "                )\n",
    "                # Calculate Jaccard for 2-grams\n",
    "                jaccard_2gram, intersection_2gram, union_2gram = jaccard_similarity(\n",
    "                    set(sentence1[\"2-grams\"]), set(sentence2[\"2-grams\"])\n",
    "                )\n",
    "\n",
    "                # Print the results\n",
    "                print(f\"Jaccard Similarity (Sentence {i+1} vs. Sentence {j+1}):\")\n",
    "                print(f\"\\t1-grams: {jaccard_1gram}\")\n",
    "                print(\n",
    "                    f\"\\tUnion 1-gram: {union_1gram}, Intersection 1-gram: {intersection_1gram}\"\n",
    "                )\n",
    "                print(f\"\\t2-grams: {jaccard_2gram}\")\n",
    "                print(\n",
    "                    f\"\\tUnion 2-gram: {union_2gram}, Intersection 2-gram: {intersection_2gram}\"\n",
    "                )\n",
    "                print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags and Grams:\n",
      "Sentence 1:\n",
      "\t1-grams: ['DT', 'NNS', 'VBP', 'JJ']\n",
      "\t2-grams: [('DT', 'NNS'), ('NNS', 'VBP'), ('VBP', 'JJ')]\n",
      "---------------------------------------------------------------------------------\n",
      "Sentence 2:\n",
      "\t1-grams: ['NNP', 'VBZ', 'DT', 'NN']\n",
      "\t2-grams: [('NNP', 'VBZ'), ('VBZ', 'DT'), ('DT', 'NN')]\n",
      "---------------------------------------------------------------------------------\n",
      "Sentence 3:\n",
      "\t1-grams: ['NNP', 'VBZ', 'JJ']\n",
      "\t2-grams: [('NNP', 'VBZ'), ('VBZ', 'JJ')]\n",
      "---------------------------------------------------------------------------------\n",
      "Jaccard Similarity (Sentence 1 vs. Sentence 2):\n",
      "\t1-grams: 0.14285714285714285\n",
      "\tUnion 1-gram: 7, Intersection 1-gram: 1\n",
      "\t2-grams: 0.0\n",
      "\tUnion 2-gram: 6, Intersection 2-gram: 0\n",
      "-------------------------------------------------------\n",
      "Jaccard Similarity (Sentence 1 vs. Sentence 3):\n",
      "\t1-grams: 0.16666666666666666\n",
      "\tUnion 1-gram: 6, Intersection 1-gram: 1\n",
      "\t2-grams: 0.0\n",
      "\tUnion 2-gram: 5, Intersection 2-gram: 0\n",
      "-------------------------------------------------------\n",
      "Jaccard Similarity (Sentence 2 vs. Sentence 1):\n",
      "\t1-grams: 0.14285714285714285\n",
      "\tUnion 1-gram: 7, Intersection 1-gram: 1\n",
      "\t2-grams: 0.0\n",
      "\tUnion 2-gram: 6, Intersection 2-gram: 0\n",
      "-------------------------------------------------------\n",
      "Jaccard Similarity (Sentence 2 vs. Sentence 3):\n",
      "\t1-grams: 0.4\n",
      "\tUnion 1-gram: 5, Intersection 1-gram: 2\n",
      "\t2-grams: 0.25\n",
      "\tUnion 2-gram: 4, Intersection 2-gram: 1\n",
      "-------------------------------------------------------\n",
      "Jaccard Similarity (Sentence 3 vs. Sentence 1):\n",
      "\t1-grams: 0.16666666666666666\n",
      "\tUnion 1-gram: 6, Intersection 1-gram: 1\n",
      "\t2-grams: 0.0\n",
      "\tUnion 2-gram: 5, Intersection 2-gram: 0\n",
      "-------------------------------------------------------\n",
      "Jaccard Similarity (Sentence 3 vs. Sentence 2):\n",
      "\t1-grams: 0.4\n",
      "\tUnion 1-gram: 5, Intersection 1-gram: 2\n",
      "\t2-grams: 0.25\n",
      "\tUnion 2-gram: 4, Intersection 2-gram: 1\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define your sentences\n",
    "# NOTE: The name Secretes is written in uppercase because the library detects it as a NNS instead of NNP since the begging of the sentence starts with Uppercase.\n",
    "sentences = [\"All men are mortal\", \"SOCRATES is a man\", \"SOCRATES is mortal\"]\n",
    "\n",
    "# Get POS-tagged sentences\n",
    "pos_tagged_sentences = get_pos_tags(sentences)\n",
    "\n",
    "# Get POS 1-grams and 2-grams for each sentence\n",
    "grams_dict = get_grams(pos_tagged_sentences)\n",
    "\n",
    "# Print POS Tags and Grams\n",
    "print(\"POS Tags and Grams:\")\n",
    "for key, value in grams_dict.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(f\"\\t1-grams: {value['1-grams']}\")\n",
    "    print(f\"\\t2-grams: {value['2-grams']}\")\n",
    "    print(\n",
    "        \"---------------------------------------------------------------------------------\"\n",
    "    )\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "calculate_jaccard(grams_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
